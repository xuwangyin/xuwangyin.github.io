<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="./asset/bootstrap.min.css">
		<link rel="stylesheet" type="text/css" href="./asset/style.css">
		<link href="./asset/css" rel="stylesheet" type="text/css">
		<link href="./asset/css(1)" rel="stylesheet" type="text/css">
		<link href="./asset/css(2)" rel="stylesheet" type="text/css">

		<script type="text/javascript" src="./asset/bootstrap.min.js.download"></script>

		<title>Xuwang Yin Homepage</title>
		<script async="" src="./asset/js"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-BWPFJD8HYS');
		</script>
	</head>
	<body>
		<div class="container">
			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h1 class="title">Xuwang Yin</h1>
				</div>
			</div> <!-- class="row" -->
			<div class="row row-thin">
				<div class="col-md-6 text-left">
					<h4 class="header-thin">PhD student</h4>
					<h4 class="header-thin">Department of Electrical & Computer Engineering, University of Virginia</h4>
					<p><a href="https://github.com/xuwangyin/">Github</a> &nbsp <a href="https://scholar.google.com/citations?user=c425B6UAAAAJ">Google Scholar</a></p>
				</div>
				<div class="col-md-6 text-right flex-col">
					<h4 class="header-thin">Charlottesville, VA 22908, US</h4>
					<h4 class="header-thin">xy4cm@virginia.edu</h4>
<!-- 					<h4 class="header-thin">Phone: (434)3270325</h4> -->
				</div>
			</div> <!-- class="row" -->
			<div class="row row-thin">
				<div class="col-md-12">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>About me</h2>
				</div>
				<div class="col-md-12 text-thin">
					<p>I am a PhD student working in Prof. Gustavo K. Rohde's <a href="http://imagedatascience.com/">Imaging and Data Science Lab</a>.</p>
					<p>My research interests are</p>
					<ul style="margin-left: 40px;">
					  <li>Adversarial machine learning (detecting adversarial examples, robust classification)</li>
					  <li>Generative models (energy-based models)</li>
					  <li>Multimodal learning with vision + language</li>
					</ul>
				</div>
			</div> <!-- class="row" -->
			<div class="row row-thin">
				<div class="col-md-12">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Selected Publications</h2>
				</div>
			</div> <!-- class="row" -->


			<div class="row row-thin">

				<div class="col-md-3">
					<img class="img-responsive img-embeded" src="./gen.jpg">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://arxiv.org/abs/2012.06568">Learning Energy-Based Models With Adversarial Training</a></h4>
					<span><strong>Xuwang Yin</strong>, Shiying Li, Gustavo K. Rohde</span>
					<h5>European Conference on Computer Vision (ECCV), 2022</h5>
					<p style="font-size:90%;" class="text-justify">We develop a new type of generative model based on adversarial training (AT). We show that (binary) AT learns a special kind of energy function that models the support of the data distribution, and the learning process is closely related to MCMC-based maximum likelihood learning of EBMs. Our results show that this new approach is capable of generating diverse and realistic images, is stable to train, is well-suited for image translation tasks, and exhibits strong out-of-distribution adversarial robustness. Our study demonstrates the viability of the AT approach to generative modeling.
					</p>
					<h5>[<a href="https://arxiv.org/abs/2012.06568">arxiv</a>]</h5>
				</div>
			</div>
			
			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->
			
			
			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./gat.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://openreview.net/forum?id=SJeQEp4YDH">GAT: Generative Adversarial Training for Adversarial Example Detection and Robust Classification
</a></h4>
					<span><strong>Xuwang Yin</strong>, Soheil Kolouri, Gustavo K. Rohde</span>
					<h5>International Conference on Learning Representations (ICLR), 2020 </h5>
					<p style="font-size:90%;" class="text-justify">We propose a principled approach to detecting adversarial examples that can withstand adaptive adversarial attacks. We further apply the detection idea to robust classification and show that the proposed generative classifier has comparable performance to a baseline softmax robust classifier and at the same time is more interpretable.
					</p>
					<h5>[<a href="https://openreview.net/forum?id=SJeQEp4YDH">openreview</a>] [<a href="https://github.com/xuwangyin/GAT-CIFAR10">code</a>]</h5>
				</div>
			</div>
			
			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->
			
			
			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./hypersurface.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://ieeexplore.ieee.org/document/9127864">Neural Networks, Hypersurfaces, and Radon Transforms
</a></h4>
					<span>Soheil Kolouri, <strong>Xuwang Yin</strong>, Gustavo K. Rohde</span>
					<h5>IEEE Signal Processing Magazine (Lecture Notes, July 2020) </h5>
					<p style="font-size:90%;" class="text-justify">Connections between integration along hypersufaces, Radon transforms, and neural networks are exploited to
highlight an integral geometric mathematical interpretation of
neural networks.
					</p>
					<h5>[<a href="https://arxiv.org/abs/1907.02220">arxiv</a>] [<a href="https://github.com/rohdelab/radon-neural-network">code</a>]</h5>
				</div>
			</div>
			
			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->
			
			
			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./CDTNS.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://link.springer.com/article/10.1007/s10851-021-01052-0">Radon Cumulative Distribution Transform Subspace Modeling for Image Classification
</a></h4>
					<span>Mohammad Shifat-E-Rabbi, <strong>Xuwang Yin</strong>, Abu Hasnat Mohammad Rubaiyat, Shiying Li, Soheil Kolouri, Akram Aldroubi, Jonathan M. Nichols, Gustavo K. Rohde</span>
					<h5>Journal of Mathematical Imaging and Vision (2020) </h5>
<!-- 					<p style="font-size:90%;">placeholder
					</p> -->
					<h5>[<a href="https://arxiv.org/abs/2004.03669">arxiv</a>]</h5>
				</div>
			</div>
			
			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->
			
			
			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./obj2txt.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://aclanthology.org/D17-1017/">OBJ2TEXT: Generating Visually Descriptive Language from Object Layouts
</a></h4>
					<span><strong>Xuwang Yin</strong>, Vicente Ordonez</span>
					<h5>Empirical Methods in Natural Language Processing  (EMNLP), 2017, oral presentation </h5>
<!-- 					<p style="font-size:90%;">placeholder
					</p> -->
					<h5>[<a href="https://arxiv.org/abs/1707.07102">arxiv</a>] [<a href="https://github.com/uvavision/obj2text-neuraltalk2">code</a>]</h5>
				</div>
			</div>
			
			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->
			
			
			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./scenetext.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://ieeexplore.ieee.org/document/6613482">Robust Text Detection in Natural Scene Images
</a></h4>
					<span>Xu-Cheng Yin, <strong>Xuwang Yin</strong>, Kaizhu Huang, Hong-Wei Hao</span>
					<h5>IEEE transactions on pattern analysis and machine intelligence (PAMI), 2014 </h5>
<!-- 					<p style="font-size:90%;">placeholder
					</p> -->
					<h5>[<a href="https://arxiv.org/abs/1301.2628">arxiv</a>]</h5>
				</div>
			</div>

			<div class="row row-thin">
				<div class="col-md-8">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin ">

				<div class="col-md-3">
					<img class="rounded img-responsive img-embeded" src="./icpr.png">
				</div>
				<div class="col-md-9 text-thin">
					<h4><a class="blue_link" href="https://ieeexplore.ieee.org/document/6460237">Effective text localization in natural scene images with MSER, geometry-based grouping and AdaBoost
</a></h4>
					<span><strong>Xuwang Yin</strong>, Xu-Cheng Yin, Hong-Wei Hao, Khalid Iqbal</span>
					<h5>International Conference on Pattern Recognition (ICPR), 2012</h5>
					<!-- <p style="font-size:90%;">placeholder
					</p> -->
				</div>
			</div>

			<div class="row row-thin">
				<div class="col-md-12">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Teaching Experience</h2>
					<p style="font-size:110%;">Teaching Assistent (University of Virginia) </p>
					<ul style="margin-left: 40px;font-size:110%">
					  <li> CS 3501 / ECE 3502: Foundations of Data Analysis (Spring 2022)</li>
					  <li>ECE, CS 450(1/2)/6501: Statistical Learning and Graphical Models (Fall 2021)</li>
					</ul>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12">
					<hr>
				</div>
			</div> <!-- class="row" -->

			<div class="row row-thin">
				<div class="col-md-12 text-left">
					<h2>Awards and professional activities</h2>
					<p style="font-size:110%;">International Conference on Document Analysis and Recognition (ICDAR2013) robust reading competition <a href="ICDAR2013_Awards.pdf">winner</a> (out of 15 research teams from 7 countries)</p>
					<p style="font-size:110%;">Outstanding Graduate of Beijing, Beijing Municipal Commission of Education, Jan 2014.</p>
					<p style="font-size:110%;">Reviewer for Neurocomputing journal, ACL-IJCNLP 2021, EMNLP2021, ACL2022, ICLR 2022, ECCV 2022, NeurIPS 2022.</p>
				</div>
			</div> <!-- class="row" -->


		</div> <!-- class="container" -->
	
</body></html>
